import lib.Common.Utils.Constants as Constants
import lib.Common.Utils.Log as Log
import lib.Common.Utils as Utils

import json

PATHS_TOP_N_TO_CONSIDER = 20 # Top actions to build paths from
MAX_GOAL_PATH_LENGTH    = 6

def load_state_maps(connection, training_ids, target, transition_id = None):
    # Log.logger.debug([training_ids, transition_id, target])

    state_map = {}
    for game_type in Constants.GAME_TYPES:
        if transition_id is None:
            # FIRST WE GET THE SECOND HIGHEST TRANSITION ID
            query  = "SELECT DISTINCT transition_id from training_states WHERE game_type=%s AND target=%s"
            query += " AND training_id IN (%s)  ORDER BY transition_id DESC LIMIT 2" % ",".join(training_ids)
            # Log.logger.debug([query, (game_type, target)])
            results = connection.query(query, (game_type, target))
            # Log.logger.debug(results)

            if len(results) < 2:
                continue
            else:
                transition_id_to_use = results[1]['transition_id']
        else:
            transition_id_to_use = transition_id
            # Log.logger.debug(f"Will use transition_id {transition_id}")

        query = "SELECT ts.training_id, ts.state_hash, ts.state, ts.top_dqn, ts.next_states, ts.prev_states, ts.initial_state FROM training_states ts "
        query += "WHERE ts.training_id IN (%s) " % ",".join(training_ids)
        query += " AND ts.transition_id=%s"
        query += " AND ts.target =%s"
        query += " AND ts.game_type=%s"
        # Log.logger.info([query, (transition_id_to_use, target, game_type)])

        results = connection.query(query, (transition_id_to_use, target, game_type))
        # print(results)

        if len(results) == 0:
            Log.logger.warning(f"({game_type}) There is no data for training_ids {training_ids}")
            continue

        # Log.logger.debug(results)
        for result in results:
            training_id = result.pop('training_id')
            if training_id not in state_map:
                state_map[training_id] = {}
            if game_type not in state_map[training_id]:
                state_map[training_id][game_type] = {}

            state_hash = result.pop('state_hash')
            state_map[training_id][game_type][state_hash] = result

    return state_map

def build_training_path(states_map, state_hash, exploitation_paths, exploitation_path):
    # Log.logger.debug([states_map, state_hash, exploitation_paths, exploitation_path])
    # First lets check we can start the loop
    if state_hash not in states_map:
        return

    top_dqn = states_map[state_hash]["top_dqn"]
    # If top_dqn is json we parse it as a dict
    if isinstance(top_dqn, str):
        top_dqn = json.loads(top_dqn)

    # We create a copy in case there is more than one state we can go from this action
    original_exploitation_path = exploitation_path.copy()

    # Second we see if the action leads to any path in next states
    next_states = states_map[state_hash]['next_states']
    # If next_states is json we parse it as a dict
    if isinstance(next_states, str):
        next_states = json.loads(next_states)

    counter = 0
    for next_state_hash in next_states:
        # Log.logger.debug(f"Looping through next_state_hash: {next_state_hash}")
        skip_state_hash = False
        # We don't want to return to an action we already followed
        for seen_state in exploitation_path:
            if seen_state['state_hash'] == next_state_hash:
                skip_state_hash = True
                break

        if skip_state_hash:
            continue

        next_state_actions = next_states[next_state_hash]

        for action_pos in range(0, PATHS_TOP_N_TO_CONSIDER):
            # First we get the best action
            best_action = list(top_dqn.keys())[action_pos]
            # Log.logger.debug(f"Best action is {best_action} with pos {action_pos}")

            if best_action in next_state_actions:
                # Log.logger.debug(f"best_action: {best_action} is in next_state_actions")
                # We check if it has reached a goal, if that is the case we can end it here
                if 'goal_reached' in next_state_actions[best_action]:
                    # We add this action to our path
                    if counter == 0:
                        data = {
                            "state_hash": next_state_hash,
                            "action": best_action,
                            "goal_reached": True,
                            "action_pos":   action_pos,
                        }
                        exploitation_path.append(data)
                        # Log.logger.debug(f"Appending: {data}")
                    else:
                        temp_exploitation_path = original_exploitation_path.copy()
                        data = {
                            "state_hash": next_state_hash,
                            "action": best_action,
                            "goal_reached": True,
                            "action_pos": action_pos,
                        }
                        temp_exploitation_path.append(data)
                        exploitation_paths.append(temp_exploitation_path)
                        # Log.logger.debug(f"Appending: {data}")
                else:
                    if counter == 0:
                        data = {
                            "state_hash": next_state_hash,
                            "action": best_action,
                            "goal_reached": False,
                            "action_pos": action_pos,
                        }
                        exploitation_path.append(data)
                        # Log.logger.debug(f"Appending: {data}")
                        build_training_path(states_map, next_state_hash, exploitation_paths, exploitation_path)
                    else:
                        temp_exploitation_path = original_exploitation_path.copy()
                        data = {
                            "state_hash": next_state_hash,
                            "action": best_action,
                            "goal_reached": False,
                            "action_pos": action_pos,
                        }
                        temp_exploitation_path.append(data)
                        # Log.logger.debug(f"Appending: {data}")
                        exploitation_paths.append(temp_exploitation_path)
                        build_training_path(states_map, next_state_hash, exploitation_paths, temp_exploitation_path)
                counter += 1

def get_initial_state_hashes(states_map):
    initial_state_hashes = []
    for state_hash in states_map:
        is_initial_state_hash = states_map[state_hash]['initial_state']
        # Log.logger.debug([state_hash, is_initial_state_hash])
        if is_initial_state_hash == 1:
            initial_state_hashes.append(state_hash)

    return initial_state_hashes

def create_training_path(game_type, full_states_map, print_debug=True):
    """
    This should take a map where:
    state_hash => {
        "top_dqn":     top actions for the state
        "next_states": for each action to what state it might lead from there
    }

    """
    if game_type not in full_states_map:
        Log.logger.warning(f"Gametype {game_type} is not present in state maps, returning empty")
        return {}, {}, {}

    states_map = full_states_map[game_type]
    # Log.logger.debug(states_map)

    initial_state_hashes = get_initial_state_hashes(states_map)
    # Log.logger.debug(initial_state_hashes)

    all_exploitation_paths = []
    for initial_state_hash in initial_state_hashes:
        # Log.logger.debug(f"Going through initial state_hash: {initial_state_hash}")
        exploitation_paths = []
        exploitation_path = [{
            "state_hash":  initial_state_hash,
            "action":      "Begin",
            "goal_reached": False,
            "action_pos":   0,
        }]
        exploitation_paths.append(exploitation_path)
        build_training_path(states_map, initial_state_hash, exploitation_paths, exploitation_path)
        all_exploitation_paths += exploitation_paths

    if print_debug:
        Log.logger.debug("="*50)
    # Now we can filter paths for only those that reach a goal
    best_goal_paths        = []
    goal_paths             = []
    exploitation_paths_arr = []
    # Log.logger.debug(all_exploitation_paths)
    for path in all_exploitation_paths:
        path_str, reached_goal, best_goal_path = path_to_string(path)

        if print_debug:
            Log.logger.debug(path)
            Log.logger.debug(path_str)

        if reached_goal and len(path) < MAX_GOAL_PATH_LENGTH:
            goal_paths.append(path_str)

        if best_goal_path:
            best_goal_paths.append(path_str)

        exploitation_paths_arr.append(path_str)

    if print_debug:
        Log.logger.debug("=" * 50)

    return exploitation_paths_arr, goal_paths, best_goal_paths

def path_to_string(path):
    path_arr = []
    best_goal_path = True
    for action_data in path:
        if action_data['action_pos'] != 0:
            best_goal_path = False

        if action_data['action'] == "Begin":
            path_arr.append(f"{action_data['action']}({action_data['action_pos']}) => {action_data['state_hash']}")
        else:
            path_arr.append(f"=> {action_data['action']}({action_data['action_pos']}) => {action_data['state_hash']}")
        if action_data["goal_reached"]:
            path_arr.append("=> GOAL")
            return " ".join(path_arr), True, best_goal_path

    return " ".join(path_arr), False, False

# states_map = {
#     "STATE1": {
#         "top_dqn": {
#             "action1": 1,
#             "action2": 0.4,
#             "action3": 0.2,
#         },
#         "next_states": {
#             "STATE2": {
#                 "action1": {"amount": 1}
#             }
#         }
#     },
#     "STATE2": {
#         "top_dqn": {
#             "action2": 1,
#             "action1": 0.4,
#             "action3": 0.2,
#         },
#         "next_states": {
#             "STATE3": {
#                 "action2": {"amount": 1, "goal_reached": 1}
#             },
#             "STATE4": {
#                 "action2": {"amount": 1}
#             },
#         }
#     },
#     "STATE3": {
#         "top_dqn": {
#             "action3": 1,
#             "action2": 0.4,
#             "action1": 0.2,
#         },
#         "next_states": {
#
#         }
#     },
#     "STATE4": {
#         "top_dqn": {
#             "action4": 1,
#             "action2": 0.4,
#             "action1": 0.2,
#         },
#         "next_states": {
#
#         }
#     },
# }